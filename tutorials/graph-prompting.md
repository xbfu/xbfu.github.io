---
layout: page
title: KDD 2025 Tutorial
permalink: /tutorials/kdd25-graph-prompting
subtitle: Tutorials - Xingbo Fu
---


## Graph Prompting for Graph Learning Models: Recent Advances and Future Directions
<br>
<img src="https://kdd2025.kdd.org/wp-content/uploads/2024/12/logo_to_KDD-2.png" style="padding: 0.00025rem; border: 0.001px solid #dee2e6; border-radius: 0.0025em; background-size: 0.002px; background-color: #fff"/>

<br>

<li><a href="https://arxiv.org/abs/2506.08326"><div class="report">Survey paper</div></a></li>

<br>



## Abstract
<p style="text-align: justify">
Graph learning models have demonstrated great prowess in learning expressive representations from large-scale graph data in a wide variety of real-world scenarios.
As a prevalent strategy for training powerful graph learning models, the "pre-training, adaptation" scheme first pre-trains graph learning models on unlabeled graph data in a self-supervised manner and then adapts them to specific downstream tasks.
During the adaptation phase, graph prompting emerges as a promising approach that learns trainable prompts while keeping the pre-trained graph learning models unchanged.
This tutorial will conver recent advancements in graph prompting including</p>
<li>Representative graph pre-training methods that serve as the foundation step of graph prompting</li>
<li>Mainstream techniques in graph prompting and elaborate on how they design learnable prompts for graph prompting</li>
<li>Real-world applications of graph prompting from different domains</li>
<li>Open challenges in existing studies with promising future directions in this field</li>

## Presenters

<br>


<div style="display: inline-block; width: 31%;">
  <div  align="center"> 
    <img src="Xingbo.png"  style="width: 7rem; padding: 0.2rem; border: 1px solid #dee2e6; border-radius: 0.25em; background-size: 2px; background-color: #fff">
  </div>
  <center>
  <a href="https://www.xingbofu.com/">Xingbo Fu</a><br>
  University of Virginia
  </center>
</div>

<div style="display: inline-block; width: 31%;">  
  <div  align="center"> 
    <img src="Zehong.jpg"  style="width: 7rem; padding: 0.2rem; border: 1px solid #dee2e6; border-radius: 0.25em; background-size: 2px; background-color: #fff">
  </div>
  <center>
  <a href="https://zehong-wang.github.io/">Zehong Wang</a><br>
    University of Notre Dame
  </center>
</div>

<div style="display: inline-block; width: 31%;">
  <div  align="center"> 
    <img src="Jundong.png"  style="width: 7rem; padding: 0.2rem; border: 1px solid #dee2e6; border-radius: 0.25em; background-size: 2px; background-color: #fff">
  </div>
  <center>
  <a href="https://jundongli.github.io/">Jundong Li</a><br>
  University of Virginia
  </center>
</div>


## Organizers

<li><a href="https://www.xingbofu.com/">Xingbo Fu</a>, PhD student, University of Virginia</li>
<li><a href="https://zehong-wang.github.io/">Zehong Wang</a>, PhD student, University of Notre Dame</li>
<li><a href="https://chen-1031.github.io/">Zihan Chen</a>, PhD student, University of Virginia</li>
<li><a href="https://www.linkedin.com/in/jiazheng-li-730169259/">Jiazheng Li</a>, PhD student, University of Connecticut</li>
<li><a href="https://www.ychzhu.com/">Yaochen Zhu</a>, PhD student, University of Virginia</li>
<li><a href="https://lzyfischer.github.io/">Zhenyu Lei</a>, PhD student, University of Virginia</li>
<li><a href="https://cshen317.github.io/">Cong Shen</a>, Associate Professor, University of Virginia</li>
<li><a href="http://yes-lab.org/">Yanfang Ye</a>, Galassi Family Collegiate Professor, University of Notre Dame</li>
<li><a href="https://chuxuzhang.github.io/">Chuxu Zhang</a>, Associate Professor, University of Connecticut</li>
<li><a href="https://jundongli.github.io/">Jundong Li</a>, Associate Professor, University of Virginia</li>
